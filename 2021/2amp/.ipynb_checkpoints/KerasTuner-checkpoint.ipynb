{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kerastuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "models        = []\n",
    "strategyArray = []\n",
    "gainArray     = []\n",
    "lossArray     = []\n",
    "ampNumber     = 2\n",
    "\n",
    "originalDataSet = pd.read_csv('dataset.txt', sep = ',',header = None)\n",
    "originalDataSet = originalDataSet.sample(frac = 1, random_state = 5)\n",
    "\n",
    "binaryDataSet   = []\n",
    "\n",
    "for line in originalDataSet.values:\n",
    "    myList = [1 if i != 0 else 0 for i in line[:40]]\n",
    "    myList.extend(line[40:])\n",
    "    binaryDataSet.append(myList)\n",
    "\n",
    "binaryDataSet = pd.DataFrame(binaryDataSet)\n",
    "gainScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "lossScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "\n",
    "gainScalerAux = []\n",
    "lossScalerAux = []\n",
    "\n",
    "for i in range(0, ampNumber * 2, 2):\n",
    "    gainScalerAux.extend(binaryDataSet.values[:, 40 + i])\n",
    "    lossScalerAux.extend(binaryDataSet.values[:, 40 + i + 1])\n",
    "\n",
    "gainScaler.fit(np.array(gainScalerAux).reshape(-1, 1))\n",
    "lossScaler.fit(np.array(lossScalerAux).reshape(-1, 1))\n",
    "\n",
    "def loadDataset(): \n",
    "    dataSet = binaryDataSet.values[:, :40]\n",
    "    \n",
    "    for i in range(0, ampNumber * 2, 2):\n",
    "        gain    = np.array(binaryDataSet.values[:, 40 + i])\n",
    "        gain    = gainScaler.transform(gain.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, gain))\n",
    "        \n",
    "        loss    = np.array(binaryDataSet.values[:, 40 + i + 1])\n",
    "        loss    = lossScaler.transform(loss.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, loss))\n",
    "            \n",
    "    X, y = np.array(dataSet[:, :40]), np.array(dataSet[:, 40:])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def invertGainNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return round(gainScaler.inverse_transform(auxArray)[0][0])\n",
    "\n",
    "def invertLossNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return round(lossScaler.inverse_transform(auxArray)[0][0])\n",
    "    \n",
    "def getGainError(value1, value2):\n",
    "    return abs(invertGainNorm(value1) - invertGainNorm(value2))\n",
    "\n",
    "def getLossError(value1, value2):\n",
    "    return abs(invertLossNorm(value1) - invertLossNorm(value2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModels():\n",
    "    models = []\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        tuner = kt.tuners.BayesianOptimization(\n",
    "                    kt.applications.HyperResNet(input_shape=(1, 4)),\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials=50)\n",
    "        \n",
    "        models.append(tuner)\n",
    "    \n",
    "    return models\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(regressor, X, y, folds = 5):\n",
    "    foldSize   = math.ceil(X.shape[0] / folds)\n",
    "    gainErrors = []\n",
    "    lossErrors = []\n",
    "    \n",
    "    for i in range(folds): \n",
    "        sliceBegin = i * foldSize\n",
    "        sliceEnd   = (i + 1) * foldSize\n",
    "        \n",
    "        X_train = np.delete(X, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        y_train = np.delete(y, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        \n",
    "        regressor.fit(X_train, y_train, verbose = False)\n",
    "        X_test = X[sliceBegin: sliceEnd]\n",
    "        y_test = y[sliceBegin: sliceEnd]\n",
    "        \n",
    "        gainError = 0\n",
    "        lossError = 0\n",
    "        \n",
    "        prediction = regressor.predict(X_test)\n",
    "        \n",
    "        for predicted, expected in zip(prediction, y_test):\n",
    "            gainError += getGainError(predicted[0], expected[0]) \n",
    "            lossError += getLossError(predicted[1], expected[1])\n",
    "                 \n",
    "        gainErrors.append((gainError / ampNumber) / foldSize)\n",
    "        lossErrors.append((lossError / ampNumber) / foldSize) # average loss error by amp\n",
    "        \n",
    "    return np.array(gainErrors), np.array(lossErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainModel(models):   \n",
    "    X, y                   = loadDataset()\n",
    "    print(X.shape)\n",
    "    gainErrors, lossErrors = crossValidate(models[0], X, y[:, 0: 2])\n",
    "    print(gainErrors, \"=> %0.2f (+/- %0.2f)\" % (np.mean(gainErrors), gainErrors.std() * 2))\n",
    "    print(lossErrors, \"=> %0.2f (+/- %0.2f)\\n\" % (np.mean(lossErrors), lossErrors.std() * 2))\n",
    "    \n",
    "    gainArray.append(gainErrors)\n",
    "    lossArray.append(lossErrors)\n",
    "    strategyArray.append(\"ANN - Amp 1\")\n",
    "    \n",
    "    prediction = models[0].predict(X)\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        #gainErrors, lossErrors = crossValidate(models[i], X, y[:, i * 2: i * 2 + 2]) \n",
    "        gainErrors, lossErrors = crossValidate(models[i], np.hstack((X, prediction)), y[:, i * 2: i * 2 + 2])  \n",
    "        print(gainErrors, \"=> %0.2f (+/- %0.2f)\" % (np.mean(gainErrors), gainErrors.std() * 2))\n",
    "        print(lossErrors, \"=> %0.2f (+/- %0.2f)\\n\" % (np.mean(lossErrors), lossErrors.std() * 2))\n",
    "\n",
    "        gainArray.append(gainErrors)\n",
    "        lossArray.append(lossErrors)\n",
    "        strategyArray.append(\"ANN - Amp {}\".format(i + 1))\n",
    "        \n",
    "        prediction = models[i].predict(np.hstack((X, prediction)))\n",
    "        #prediction = models[i].predict(X)\n",
    "    \n",
    "    return gainErrors, lossErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistribution(models):\n",
    "    train_results = []\n",
    "    test_results  = []\n",
    "    features, result                 = loadDataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.3, random_state = 5)\n",
    "    \n",
    "    models[0].fit(X_train, y_train[:, 0: 2])\n",
    "    train_results.append(models[0].predict(X_train))\n",
    "    test_results.append(models[0].predict(X_test))\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        models[i].fit(np.hstack((X_train, train_results[i - 1])), y_train[:, i * 2: i * 2 + 2])\n",
    "        train_results.append(models[i].predict(np.hstack((X_train, train_results[i - 1]))))\n",
    "        test_results.append(models[i].predict(np.hstack((X_test, test_results[i - 1]))))\n",
    "    \n",
    "    fig   = plt.figure(figsize = (15, 5))\n",
    "    vGain = np.vectorize(invertGainNorm)\n",
    "    vLoss = np.vectorize(invertLossNorm)\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        ax = fig.add_subplot(2, 2, i + 1)\n",
    "        \n",
    "        yGain    = vGain(y_test[:, i * 2])\n",
    "        yLoss    = vLoss(y_test[:, i * 2 + 1])\n",
    "        testGain = vGain(test_results[i][:, 0])\n",
    "        testLoss = vLoss(test_results[i][:, 1])\n",
    "        \n",
    "        ax.scatter(yGain, yLoss)\n",
    "        ax.scatter(testGain, testLoss, c = \"m\")\n",
    "        ax.set_title(\"Amplifier {}\".format(i + 1))\n",
    "    \n",
    "    fig.suptitle(\"Test Error\", fontsize = 16)\n",
    "    fig.text(0.5, 0.04, 'Gain', ha='center', va='center', fontsize = 14)\n",
    "    fig.text(0.06, 0.5, 'Loss', ha='center', va='center', rotation='vertical', fontsize = 14)\n",
    "    fig.legend([\"expected\", \"predicted\"])\n",
    "\n",
    "    plt.show()\n",
    "    return y_test, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGainError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    data      = []\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        gainError = []\n",
    "        \n",
    "        yTestAmp     = yTest[:, i * 2]\n",
    "        predictedAmp = predicted[i][:, 0]\n",
    "        \n",
    "        for a, b in zip(predictedAmp, yTestAmp):\n",
    "            gainError.append(getGainError(a, b)) \n",
    "        \n",
    "        data.append(gainError)\n",
    "        \n",
    "    axis.boxplot(data)\n",
    "    axis.set_title(\"Test Gain Error\", fontsize = 16)\n",
    "    axis.set_xticklabels(np.repeat(strategyArray, 1))\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    data      = []\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        lossError = []\n",
    "        \n",
    "        yTestAmp     = yTest[:, i * 2 + 1]\n",
    "        predictedAmp = predicted[i][:, 1]\n",
    "        \n",
    "        for a, b in zip(predictedAmp, yTestAmp):\n",
    "            lossError.append(getLossError(a, b)) \n",
    "        \n",
    "        data.append(lossError)\n",
    "        \n",
    "    axis.boxplot(data)\n",
    "    axis.set_title(\"Test Loss Error\", fontsize = 16)\n",
    "    axis.set_xticklabels(np.repeat(strategyArray, 1))\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLinkTestError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    lossData  = [] \n",
    "    gainData  = [] \n",
    "    \n",
    "    yTestGain     = yTest[:, 0]\n",
    "    yTestLoss     = yTest[:, 1]\n",
    "    predictedGain = np.array(predicted[0][:, 0]).flatten()\n",
    "    predictedLoss = np.array(predicted[0][:, 1]).flatten()\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        yTestGain     = np.hstack((yTestGain, yTest[:, i * 2]))\n",
    "        yTestLoss     = np.hstack((yTestLoss, yTest[:, i * 2 + 1]))\n",
    "        predictedGain = np.hstack((predictedGain, np.array(predicted[i][:, 0]).flatten()))\n",
    "        predictedLoss = np.hstack((predictedLoss, np.array(predicted[i][:, 1]).flatten()))\n",
    "    \n",
    "    for i in range(len(yTestGain)):\n",
    "        lossData.append(getLossError(predictedLoss[i], yTestLoss[i]))\n",
    "        gainData.append(getGainError(predictedGain[i], yTestGain[i]))\n",
    "            \n",
    "    print(\"Loss error mean: {}. Loss error median: {}\".format(np.mean(lossData), np.median(lossData)))\n",
    "    print(\"Gain error mean: {}. Gain error median: {}\".format(np.mean(gainData), np.median(gainData)))\n",
    "    \n",
    "    axis.boxplot([lossData, gainData])\n",
    "    axis.set_title(\"Link Test Error\", fontsize = 16)\n",
    "    axis.set_xticklabels([\"Gain\", \"Loss\"])\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearningCurves(ampNumber, model, X, y, cv):\n",
    "    fig, axis                              = plt.subplots(figsize = (10, 5))\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = cv, \n",
    "                                                            train_sizes = np.linspace(0.1, 1.0, 6),\n",
    "                                                            scoring = \"neg_mean_squared_error\")\n",
    "       \n",
    "    train_scores = -train_scores\n",
    "    test_scores  = -test_scores\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "    train_scores_std  = np.std(train_scores, axis = 1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis = 1)\n",
    "    test_scores_std   = np.std(test_scores, axis = 1)\n",
    "    \n",
    "    print(\"Size splits: {}\".format(train_sizes))\n",
    "    print(\"Train scores: {} \".format(train_scores_mean))\n",
    "    print(\"Test scores: {} \".format(test_scores_mean))\n",
    "\n",
    "    # Plot learning curve\n",
    "    axis.plot(train_sizes, train_scores_mean, 'o-', color = \"r\", label = \"Training score\")\n",
    "    axis.plot(train_sizes, test_scores_mean, 'o-', color = \"g\", label = \"Test score\")\n",
    "    axis.set_title(\"Learning Error - Amplifier {}\".format(ampNumber + 1), fontsize = 16)\n",
    "    axis.set_xlabel(\"Train size\", fontsize = 14)\n",
    "    axis.set_ylabel(\"MSE\", fontsize = 14)\n",
    "    axis.legend(loc = \"best\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gainArray = []\n",
    "lossArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1909, 40)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-36e5cfd2d562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#models = initModels()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-1612709b9b36>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m                   \u001b[0;34m=\u001b[0m \u001b[0mloadDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgainErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossErrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgainErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"=> %0.2f (+/- %0.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgainErrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgainErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"=> %0.2f (+/- %0.2f)\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossErrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "models = initModels()\n",
    "trainModel(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yTest, predicted = plotDistribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGainError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotLossError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLinkTestError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadDataset()\n",
    "\n",
    "plotLearningCurves(0, models[0], X, y[:, 0: 2], 5)\n",
    "prediction = models[0].predict(X)\n",
    "\n",
    "for i in range(1, ampNumber):\n",
    "    newX = np.hstack((X, prediction))\n",
    "    \n",
    "    plotLearningCurves(i, models[i], X, y[:, i * 2 : i * 2 + 2], 5)\n",
    "    prediction = models[i].predict(newX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acopEnv",
   "language": "python",
   "name": "acopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
